# Contributing to the AI Security Framework

> Help make AI automation safer for everyone

---

## Why Contribute

The AI agent security landscape evolves weekly. New attack vectors are discovered, new mitigations are developed, and new tools emerge. No single person or team can keep up alone. This framework improves through community contributions.

---

## What We Need

### High Priority

1. **Real-world incident reports** (anonymized)
   - What happened?
   - How was it detected?
   - What was the resolution?

2. **New attack vectors**
   - Prompt injection techniques
   - Credential extraction methods
   - Session hijacking patterns

3. **Better mitigations**
   - Configurations that work
   - Tools and scripts
   - Monitoring approaches

4. **Tool-specific guidance**
   - Claude in Chrome hardening
   - Other browser agents
   - CLI-based agents

### Always Welcome

- Typo fixes and clarifications
- Additional checklist items
- Better explanations
- Example configurations
- Translation to other languages

---

## Contribution Process

### For Small Changes (typos, clarifications)

1. Fork the repository
2. Make your change
3. Submit a pull request with clear description

### For New Content

1. Open an issue first to discuss
2. Get feedback on approach
3. Fork and create your content
4. Submit PR with:
   - Clear description of addition
   - Why it's valuable
   - Any caveats or limitations

### For Security Vulnerabilities

If you've found a security issue with this framework itself:

1. **Do not** open a public issue
2. Email: [security contact]
3. Include:
   - Description of vulnerability
   - Steps to reproduce
   - Potential impact
   - Suggested fix (if any)

---

## Content Guidelines

### Tone

- Practical over theoretical
- Actionable over abstract
- Clear over clever
- Honest about limitations

### Format

- Follow existing document structure
- Use consistent heading levels
- Include both explanation AND actionable steps
- Provide examples where helpful

### Quality Bar

Before submitting, verify:

- [ ] Content is accurate (cite sources for claims)
- [ ] Examples actually work
- [ ] No sensitive information included
- [ ] Consistent with existing framework philosophy
- [ ] Adds clear value for users

---

## What We Don't Accept

- Promotional content for specific products
- Unverified security claims
- Content that could enable attacks
- Low-effort "me too" additions
- Content that contradicts core principles without strong justification

---

## Recognition

Contributors will be:

- Listed in CONTRIBUTORS.md (if desired)
- Credited in relevant documents
- Thanked publicly (if comfortable)

---

## Questions

Open an issue with the "question" label, or reach out to maintainers directly.

---

## License

By contributing, you agree that your contributions will be licensed under the same MIT license as the project.

---

*Thank you for helping make AI automation safer.*
